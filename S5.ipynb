{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-23T06:03:11.953324Z",
     "start_time": "2021-08-23T06:03:10.185381Z"
    }
   },
   "outputs": [],
   "source": [
    "# For data frames:\n",
    "import pandas as pd\n",
    "\n",
    "# For arrays:\n",
    "import numpy as np\n",
    "\n",
    "# For optimization:\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, RocCurveDisplay\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For plotting:\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For OLS regression:\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised learning using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supervised learning is a type of machine learning (ML) that involves predicting a ground truth. And we must have some examples in order to \"supervise\" the learning algorithm.\n",
    "\n",
    "We'll demonstrate this by predicting whether borrowers will default on a loan. We know the ground truth: whether they have or not. And we will supervise the algorithm as it learns how to predict this fact.\n",
    "\n",
    "This task is a **classification** task: the loan can be in a discrete state of defaulted or not defaulted. If we are trying to predict which state/**class** a loan will end up in, it's a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load loans dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df = pd.read_csv('Loan_Default.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loans_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df['Default'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import sklearn.metrics as metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML-specific cleaning & processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A LoanID column will not generalize, and should be excluded\n",
    "loans_df.drop(columns=['LoanID'], inplace=True)\n",
    "loans_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These 3 columns are Yes/No...\n",
    "print(loans_df['HasMortgage'].unique())\n",
    "print(loans_df['HasDependents'].unique())\n",
    "print(loans_df['HasCoSigner'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... so convert them to boolean True/False. (or 1/0 would also work)\n",
    "loans_df['HasMortgage'] = (loans_df['HasMortgage'] == 'Yes')\n",
    "loans_df['HasDependents'] = (loans_df['HasDependents'] == 'Yes')\n",
    "loans_df['HasCoSigner'] = (loans_df['HasCoSigner'] == 'Yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loans_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 non-binary text columns remaining that need to be converted to a numerical format somehow.\n",
    "\n",
    "One-hot encoding is a standard way of doing so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(loans_df['Education'].unique())\n",
    "print(loans_df['EmploymentType'].unique())\n",
    "print(loans_df['MaritalStatus'].unique())\n",
    "print(loans_df['LoanPurpose'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstration of one-hot encoding on the Education column\n",
    "temp_df = pd.get_dummies(data = loans_df, columns=['Education'])\n",
    "\n",
    "print(temp_df.columns.values)\n",
    "\n",
    "temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll run it on all 4 columns:\n",
    "loans_df = pd.get_dummies(data = loans_df, columns=['Education', 'EmploymentType', 'MaritalStatus', 'LoanPurpose'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything is now a bool, int or float\n",
    "loans_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting columns into Y,X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into the labels Y and predictors X\n",
    "\n",
    "# What we want to predict\n",
    "Y = loans_df['Default']\n",
    "\n",
    "# Everything else\n",
    "X = loans_df.drop(columns=['Default'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting rows into training & test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and test/holdout/out-of-sample sets\n",
    "train_X, test_X, train_Y, test_Y = train_test_split(X, Y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_Y.shape)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_Y.shape)\n",
    "print(test_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and evaluating a RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a classifier using a RandomForest algorithm...\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=10)\n",
    "\n",
    "# ... and fit it to our training data\n",
    "model.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating on the same training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this trained model to generate predictions for the training data\n",
    "train_Y_pred = model.predict(train_X)\n",
    "train_Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well do those predictions perform?\n",
    "confusion = confusion_matrix(y_true = train_Y, y_pred = train_Y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negatives, false_positives, false_negatives, true_positives = confusion.ravel()\n",
    "\n",
    "print('Count of true negatives (predicted 0, true 0)  =  ' + str(true_negatives))\n",
    "print('Count of false negatives (predicted 0, true 1)  =  ' + str(false_negatives))\n",
    "print('Count of false positives (predicted 1, true 0)  =  ' + str(false_positives))\n",
    "print('Count of true positives (predicted 1, true 1)  =  ' + str(true_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler measure of classification accuracy:\n",
    "(train_Y == train_Y_pred).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating out-of-sample on the test/holdout data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this trained model to generate predictions for the test data\n",
    "test_Y_pred = model.predict(test_X)\n",
    "test_Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well do those predictions perform?\n",
    "confusion = confusion_matrix(y_true = test_Y, y_pred = test_Y_pred)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_negatives, false_positives, false_negatives, true_positives = confusion.ravel()\n",
    "\n",
    "print('Count of true negatives (predicted 0, true 0)  =  ' + str(true_negatives))\n",
    "print('Count of false negatives (predicted 0, true 1)  =  ' + str(false_negatives))\n",
    "print('Count of false positives (predicted 1, true 0)  =  ' + str(false_positives))\n",
    "print('Count of true positives (predicted 1, true 1)  =  ' + str(true_positives))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simpler measure of classification accuracy:\n",
    "print('Prediction accuracy rate = ', str((test_Y == test_Y_pred).mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RocCurveDisplay.from_estimator(model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try with a different set of hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & fit\n",
    "model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "model.fit(train_X, train_Y)\n",
    "\n",
    "# Evaluate on the test data\n",
    "test_Y_pred = model.predict(test_X)\n",
    "print('Prediction accuracy rate = ', str((test_Y == test_Y_pred).mean()))\n",
    "\n",
    "RocCurveDisplay.from_estimator(model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `n_estimators=100` produces better out-of-sample results than using `n_estimators=10`.\n",
    "\n",
    "There are other hyperparameters that could be set, too. See the full list at \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "\n",
    "How about systematically picking the value of these hyperparameters? This is called \"hyperparameter tuning\", and we can do this with cross-validation. \n",
    "\n",
    "It can be computationally expensive, so I will leave cross-validation for a homework exercise later.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explaining the most important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determining the most important \"features\" (i.e. predictive variables) and how the model arrives at its predictions is an important ongoing area of research in ML. There are both model-specific and general-purpose ways of getting at both questions.\n",
    "\n",
    "The RandomForest classification algorithm has a convenient way of describing these:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances_df = pd.DataFrame({\n",
    "    'feature_name' : train_X.columns.values\n",
    "    , 'feature_importance' : model.feature_importances_\n",
    "})\n",
    "importances_df.sort_values(by='feature_importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few observations:\n",
    "* As you can see, we don't learn much about the direction of the effect (although we can guess, in the case of credit scores). \n",
    "* This is dependent on the RandomForest algorithm; the code above won't work for other algorithms.\n",
    "\n",
    "There is no silver bullet. In my own research, I've found [SHAP values](https://shap.readthedocs.io/en/latest/index.html) are very helpful, but it depends on the application, so you'll just have to experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try another algorithm: a Linear Support Vector Machine classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create & fit\n",
    "model = LinearSVC(random_state=42, penalty='l2')\n",
    "model.fit(train_X, train_Y)\n",
    "\n",
    "# Evaluate on the test data\n",
    "test_Y_pred = model.predict(test_X)\n",
    "print('Prediction accuracy rate = ', str((test_Y == test_Y_pred).mean()))\n",
    "\n",
    "RocCurveDisplay.from_estimator(model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try scaling the data first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scikit-learn allows us to compose a preprocessing step (and more) followed by an ML model.\n",
    "\n",
    "Here, the preprocessing step computes the z-scores of the data (zero mean, unit variance), which often improves the performance of ML models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"model\" is now a \"pipeline\"\n",
    "model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LinearSVC(random_state=42, penalty='l2')\n",
    ")\n",
    "model.fit(train_X, train_Y)\n",
    "\n",
    "# Evaluate on the test data\n",
    "test_Y_pred = model.predict(test_X)\n",
    "print('Prediction accuracy rate = ', str((test_Y == test_Y_pred).mean()))\n",
    "\n",
    "RocCurveDisplay.from_estimator(model, test_X, test_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a schematic illustration of how cross-validation splits the data to help find a good set of hyperparameters:\n",
    "\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" />\n",
    "\n",
    "And here's some code to run it easily using scikit-learn.\n",
    "\n",
    "(Be careful if you are working with timeseries data, or data with a time dimension: you should take that into account, as in this example: https://otexts.com/fpp3/tscv.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross validation for a RandomForestClassifier\n",
    "if False:\n",
    "\n",
    "    # Step 1: run cross-validation on the training data\n",
    "    # This involves splitting the data 5 times and fitting 4*3=12 models on each split (\"fold\"), \n",
    "    # for a total of 5*12 = 60 fits. This will take some time!\n",
    "    # Then it will pick the model-hyperparameter combination that performs best on average across the 5 splits, and refit to the entire training data.\n",
    "    # This will take some time!\n",
    "    number_of_cross_validation_splits = 5\n",
    "    possible_hyperparameter_values = {\n",
    "        'n_estimators': [20, 50, 100, 200]\n",
    "        , 'max_depth': [5, 7, 9]\n",
    "    }\n",
    "    cv_model = GridSearchCV(RandomForestClassifier, possible_hyperparameter_values, cv=number_of_cross_validation_splits)\n",
    "    cv_model.fit(train_X, train_Y)\n",
    "    \n",
    "    # Step 2: print out the optimal parameter values\n",
    "    print(cv_model.best_params_) \n",
    "    # Similarly you can inspect the grid scores using cv_model.cv_results_\n",
    "    \n",
    "    # Step 3: Evaluate optimal model on the test data\n",
    "    test_Y_pred = cv_model.predict(test_X)\n",
    "    print('Prediction accuracy rate = ', str((test_Y == test_Y_pred).mean()))\n",
    "    \n",
    "    RocCurveDisplay.from_estimator(cv_model, test_X, test_Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLS Regression using statsmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:26.822549Z",
     "start_time": "2021-08-22T15:06:26.367159Z"
    }
   },
   "outputs": [],
   "source": [
    "howell_df = pd.read_csv('Howell1.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset consists of measurements of the Khosan people:\n",
    "* Sex\n",
    "* Age (years)\n",
    "* Weight (kg)\n",
    "* Total height (cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:26.837205Z",
     "start_time": "2021-08-22T15:06:26.824712Z"
    }
   },
   "outputs": [],
   "source": [
    "# Start by looking at adults\n",
    "howell_adults_df = howell_df[howell_df['age'] >= 18] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:26.852278Z",
     "start_time": "2021-08-22T15:06:26.839081Z"
    }
   },
   "outputs": [],
   "source": [
    "howell_adults_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell_adults_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:27.217323Z",
     "start_time": "2021-08-22T15:06:26.853835Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.regplot(data=howell_adults_df, x='weight', y='height')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a univariate regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"height ~ weight\", data=howell_adults_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a multivariate regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:27.229449Z",
     "start_time": "2021-08-22T15:06:27.219058Z"
    }
   },
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"height ~ weight + age + male\", data=howell_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worried about heteroscedasticity? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heteroscedasticity is a major concern in econometrics: `statsmodels` allows you to use different methods to compute your standard errors to deal with this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:27.255890Z",
     "start_time": "2021-08-22T15:06:27.252130Z"
    }
   },
   "outputs": [],
   "source": [
    "rob_result = model.fit().get_robustcov_results(cov_type='HC3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:27.272553Z",
     "start_time": "2021-08-22T15:06:27.258073Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(rob_result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Worried about outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any extreme outliers in our data. If there were, and they were distorting the regression results, some fields are fine with excluding them or [winsorizing them](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mstats.winsorize.html) - as long as this is transparently reported in your study, of course. Otherwise, consider using [robust regression](https://www.statsmodels.org/stable/rlm.html) models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond adults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sub-sample of adults\n",
    "sns.regplot(data=howell_adults_df, x='age', y='height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entire sample\n",
    "sns.regplot(data=howell_df, x='age', y='height')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"height ~ weight + age + male\", data=howell_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:06:27.234625Z",
     "start_time": "2021-08-22T15:06:27.231233Z"
    }
   },
   "outputs": [],
   "source": [
    "# Adding a quadratic term:\n",
    "model = smf.ols(formula=\"height ~ weight + age + np.power(age, 2) + male\", data=howell_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicollinearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a warning above about potential numerical problems, such as multicollinearity in the variables. \n",
    "\n",
    "Let's check for that in a heuristic way using [Variance Inflation Factors](https://en.wikipedia.org/wiki/Variance_inflation_factor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = model.exog\n",
    "vif = [variance_inflation_factor(variables, i) for i in range(variables.shape[1])]\n",
    "vif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the third variable (age) is problematic, so let's run without it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a quadratic term:\n",
    "model = smf.ols(formula=\"height ~ weight + np.power(age, 2) + male\", data=howell_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "howell_df[['weight', 'age', 'male']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = model.exog\n",
    "vif = [variance_inflation_factor(variables, i) for i in range(variables.shape[1])]\n",
    "vif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Producing $\\LaTeX$ for your research paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result.summary().as_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz: Revisiting Starbucks \n",
    "\n",
    "* Suppose you intend to examine whether sodium contributes to an increase in calories. \n",
    "* Also suppose you know sugar and trans fat have been strong factors for high calories. \n",
    "* Taken together, you want to see the association between sodium and calories while controlling for sugar and trans fat. \n",
    "* (1) Draw three plots, each of which represents the relationship between each of the three variables above and calories. (Use `regplot()` in seaborn)\n",
    "* (2) Using the `statsmodel` package, print the result of OLS regression whose formula looks like this: `Calories ~ Sodium + Sugars + TransFat`\n",
    "* (3) Once you control for sugars and tran sfar, is there a significant association between sodium and calories?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb_df = pd.read_csv('menu_starbucks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:16:59.626315Z",
     "start_time": "2021-08-22T15:16:59.622893Z"
    }
   },
   "outputs": [],
   "source": [
    "# I'll help you with some cleaning of the column names:\n",
    "sb_df.columns = sb_df.columns.str.replace(r'\\([^)]*\\)', \"\").str.rstrip(\" \").str.lstrip(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-08-22T15:17:40.547525Z",
     "start_time": "2021-08-22T15:17:40.543617Z"
    }
   },
   "outputs": [],
   "source": [
    "sb_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: part (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: part (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arrays: a case study with OLS regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to regress a variable $y$ against three variables $x_1$, $x_2$, $x_3$, and we have $i=1,..,N$ samples. Then the objective is to estimate three quantities: $\\beta_1$, $\\beta_2$, $\\beta_3$ that work for all the $N$ values of $y$ and $x_1$, $x_2$, $x_3$.\n",
    "\n",
    "$$y_i = \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i} \\quad\\text{for}\\quad i=1,..,N$$\n",
    "\n",
    "Really, we have $N$ rows for which this must hold:\n",
    "$$y_1 = \\beta_1 x_{1,1} + \\beta_2 x_{2,1} + \\beta_3 x_{3,1}$$\n",
    "$$\\ldots$$\n",
    "$$y_i = \\beta_1 x_{1,i} + \\beta_2 x_{2,i} + \\beta_3 x_{3,i}$$\n",
    "$$\\ldots$$\n",
    "$$y_N = \\beta_1 x_{1,N} + \\beta_2 x_{2,N} + \\beta_3 x_{3,N}$$\n",
    "\n",
    "The system of equations above can be represented using matrix multiplication:\n",
    "\n",
    "$$ \\begin{bmatrix} \n",
    "        y_1 \\\\ \\vdots \\\\ y_i \\\\ \\vdots \\\\ y_N \n",
    "    \\end{bmatrix}  = \\begin{bmatrix} \n",
    "    x_{1,1} & x_{2,1} & x_{3,1} \\\\\n",
    "    & \\vdots & \\\\\n",
    "    x_{1,i} & x_{2,i} & x_{3,i} \\\\\n",
    "    & \\vdots & \\\\\n",
    "    x_{1,N} & x_{2,N} & x_{3,N}\n",
    "    \\end{bmatrix} \n",
    "    \\begin{bmatrix} \n",
    "        \\beta_1 \\\\ \\beta_2 \\\\ \\beta_3 \n",
    "    \\end{bmatrix} $$\n",
    "\n",
    "We'll write these matrices as Y, X, B:\n",
    "$$ Y = XB $$\n",
    "\n",
    "\n",
    "\n",
    "Let's solve for $B$. Pre-multiply both sides with $X^T$, the transpose of $X$:\n",
    "\n",
    "$$ X^T Y = X^T XB $$\n",
    "\n",
    "Pre-multiply both sides with $(X^TX)^{-1}$, the inverse of the product $X^T X$:\n",
    "\n",
    "$$ (X^TX)^{-1} X^T Y = (X^TX)^{-1} X^T XB $$\n",
    "\n",
    "Since $(X^TX)^{-1}$ cancels out $X^T X$, we have our exact solution:\n",
    "\n",
    "$$ B = (X^TX)^{-1} X^T Y $$\n",
    "\n",
    "So let's implement multivariate regression ourselves! We just need to know three operations:\n",
    "* matrix multiplication\n",
    "* matrix transposition\n",
    "* matrix inversion\n",
    "\n",
    "Arrays and the `numpy` package give us what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating matrices from data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = howell_adults_df[['weight', 'age', 'male']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = howell_adults_df[['height']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to calculate $X^T$, the transpose of X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.T.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `matmul` from package `numpy` (abbreviated `np`) multiplies two matrices. \n",
    "\n",
    "So to calculate $X^T X$ we would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.matmul(X.T, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Quiz** Calculate $X^T Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `linalg.inv` (from the same packages) takes the inverse of a matrix.\n",
    "\n",
    "So to calculate $(X^T X)^{-1}$ we would write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.inv(np.matmul(X.T, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're almost there! \n",
    "\n",
    "**Quiz** Calculate:\n",
    "\n",
    "$B = (X^T X)^{-1} X^T Y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: put it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should get coefficient values like the ones below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"height ~ 0 + weight + age + male\", data=howell_adults_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz for later**\n",
    "\n",
    "Look up (from a textbook) how to add an intercept for the OLS solution, and then modify the above to achieve it.\n",
    "\n",
    "*Hint:* the formula is exactly the same, you need to make a change to the array `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: quiz for later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization: a case study with OLS regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLS = Ordinary Least Squares.\n",
    "\n",
    "\"Least squares\" because the optimal $\\beta$ values are those which minimize the sum of squared errors.\n",
    "\n",
    "Let's say you pick these values of beta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 2\n",
    "beta_2 = 1\n",
    "beta_3 = -5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you would predict the following values of $y_i$ for each value of $x_1$, $x_2$, $x_3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = beta_1 * howell_adults_df['weight'] + beta_2 * howell_adults_df['age'] + beta_3 * howell_adults_df['male']\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between the true values and the predictions are the errors/residuals:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = howell_adults_df['height'] - predictions\n",
    "errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The squared errors are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the sum of squared errors is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(errors**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal $\\beta$s would minimize this sum of squared errors. This is an optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sse(betas_list):\n",
    "    (beta_1, beta_2, beta_3) = betas_list\n",
    "    predictions = beta_1 * howell_adults_df['weight'] + beta_2 * howell_adults_df['age'] + beta_3 * howell_adults_df['male']\n",
    "    errors = howell_adults_df['height'] - predictions\n",
    "    sse = sum(errors**2)\n",
    "    return sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse([2, 1, -5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sse([1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.optimize.minimize(sse, [0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should get coefficient values like the ones below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols(formula=\"height ~ 0 + weight + age + male\", data=howell_adults_df)\n",
    "result = model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quiz**. \n",
    "\n",
    "Change the function `sse` to add an intercept $\\beta_0$. \n",
    "\n",
    "And then run `scipy.optimize.minimize(sse, [0,0,0,0])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
